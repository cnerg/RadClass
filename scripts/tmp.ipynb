{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostics\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "# testing models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import tests.test_data as test_data\n",
    "# hyperparameter optimization\n",
    "import ray.tune as tune\n",
    "# testing utils\n",
    "import scripts.utils as utils\n",
    "# testing write\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, n_redundant=0, n_classes=2, class_sep=2.5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "\n",
    "# normalization\n",
    "normalizer = StandardScaler()\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "# testing hyperopt optimize methods\n",
    "space = {'max_iter': tune.quniform(10, 10000, 10),\n",
    "            'tol': tune.loguniform(1e-5, 1e-1),\n",
    "            'C': tune.loguniform(0.001, 1000.0)\n",
    "            }\n",
    "data_dict = {'trainx': X_train,\n",
    "                'testx': X_test,\n",
    "                'trainy': y_train,\n",
    "                'testy': y_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def fresh_start(params, data_dict):\n",
    "    '''\n",
    "    Required method for hyperopt optimization.\n",
    "    Trains and tests a fresh logistic regression model\n",
    "    with given input parameters.\n",
    "    This method does not overwrite self.model (self.optimize() does).\n",
    "    Inputs:\n",
    "    params: dictionary of logistic regression input functions.\n",
    "        keys max_iter, tol, and C supported.\n",
    "    data_dict: compact data representation with the four requisite\n",
    "        data structures used for training and testing a model.\n",
    "        keys trainx, trainy, testx, and testy required.\n",
    "    '''\n",
    "\n",
    "    # unpack data\n",
    "    trainx = data_dict['trainx']\n",
    "    trainy = data_dict['trainy']\n",
    "    testx = data_dict['testx']\n",
    "    testy = data_dict['testy']\n",
    "    # supervised logistic regression\n",
    "    clf = linear_model.LogisticRegression(\n",
    "            random_state=0,\n",
    "            max_iter=params['max_iter'],\n",
    "            tol=params['tol'],\n",
    "            C=params['C']\n",
    "            )\n",
    "    # train and test model\n",
    "    clf.fit(trainx, trainy)\n",
    "    # uses balanced_accuracy accounts for class imbalanced data\n",
    "    pred = clf.predict(testx)\n",
    "    acc = balanced_accuracy_score(testy, pred)\n",
    "    rec = recall_score(testy, pred)\n",
    "    prec = precision_score(testy, pred)\n",
    "\n",
    "    # loss function minimizes misclassification\n",
    "    return {'score': acc+rec+prec,\n",
    "            'loss': (1-acc) + 20*(1-rec)+(1-prec),\n",
    "            'model': clf,\n",
    "            'params': params,\n",
    "            'accuracy': acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "\n",
    "algo = HyperOptSearch()\n",
    "algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "\n",
    "fmin_objective = partial(fresh_start, data_dict=data_dict)\n",
    "tuner = tune.Tuner(\n",
    "    fmin_objective, param_space=space, tune_config=tune.TuneConfig(num_samples=10, metric='score', mode='max', search_alg=algo)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-01 17:11:48 (running for 00:00:31.12)<br>Memory usage on this node: 3.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.25 GiB heap, 0.0/4.12 GiB objects<br>Current best trial: c696e676 with score=2.9168070575268152 and parameters={'max_iter': 5100.0, 'tol': 2.920856784232474e-05, 'C': 0.0031039009824053426}<br>Result logdir: /home/stomps/ray_results/fresh_start_2022-11-01_17-11-16<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">          C</th><th style=\"text-align: right;\">  max_iter</th><th style=\"text-align: right;\">        tol</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>fresh_start_b9e48de8</td><td>TERMINATED</td><td>172.21.93.86:25712</td><td style=\"text-align: right;\">221.308    </td><td style=\"text-align: right;\">      3540</td><td style=\"text-align: right;\">6.84678e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        4.2281  </td><td style=\"text-align: right;\">2.77873</td><td style=\"text-align: right;\">1.70402 </td><td style=\"text-align: right;\">  0.926372</td></tr>\n",
       "<tr><td>fresh_start_bcaf0896</td><td>TERMINATED</td><td>172.21.93.86:25741</td><td style=\"text-align: right;\">  0.189275 </td><td style=\"text-align: right;\">      6920</td><td style=\"text-align: right;\">5.91661e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.661553</td><td style=\"text-align: right;\">2.84033</td><td style=\"text-align: right;\">1.22863 </td><td style=\"text-align: right;\">  0.946824</td></tr>\n",
       "<tr><td>fresh_start_bdd4f2a8</td><td>TERMINATED</td><td>172.21.93.86:25748</td><td style=\"text-align: right;\">  0.233134 </td><td style=\"text-align: right;\">      6750</td><td style=\"text-align: right;\">0.0136973  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.755042</td><td style=\"text-align: right;\">2.8362 </td><td style=\"text-align: right;\">1.26725 </td><td style=\"text-align: right;\">  0.945461</td></tr>\n",
       "<tr><td>fresh_start_c083f26a</td><td>TERMINATED</td><td>172.21.93.86:25804</td><td style=\"text-align: right;\"> 29.5431   </td><td style=\"text-align: right;\">      8490</td><td style=\"text-align: right;\">0.000300635</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.57576 </td><td style=\"text-align: right;\">2.78147</td><td style=\"text-align: right;\">1.68405 </td><td style=\"text-align: right;\">  0.927281</td></tr>\n",
       "<tr><td>fresh_start_c16acd84</td><td>TERMINATED</td><td>172.21.93.86:25833</td><td style=\"text-align: right;\">  0.117569 </td><td style=\"text-align: right;\">      9000</td><td style=\"text-align: right;\">0.00621561 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.0258  </td><td style=\"text-align: right;\">2.85384</td><td style=\"text-align: right;\">1.1634  </td><td style=\"text-align: right;\">  0.951373</td></tr>\n",
       "<tr><td>fresh_start_c3ef62d6</td><td>TERMINATED</td><td>172.21.93.86:25748</td><td style=\"text-align: right;\">  0.850306 </td><td style=\"text-align: right;\">      7430</td><td style=\"text-align: right;\">5.77503e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.59859 </td><td style=\"text-align: right;\">2.80747</td><td style=\"text-align: right;\">1.48563 </td><td style=\"text-align: right;\">  0.935916</td></tr>\n",
       "<tr><td>fresh_start_c49f36fc</td><td>TERMINATED</td><td>172.21.93.86:25872</td><td style=\"text-align: right;\">  8.65052  </td><td style=\"text-align: right;\">      2690</td><td style=\"text-align: right;\">4.11847e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        3.10422 </td><td style=\"text-align: right;\">2.78562</td><td style=\"text-align: right;\">1.64541 </td><td style=\"text-align: right;\">  0.928644</td></tr>\n",
       "<tr><td>fresh_start_c696e676</td><td>TERMINATED</td><td>172.21.93.86:25804</td><td style=\"text-align: right;\">  0.0031039</td><td style=\"text-align: right;\">      5100</td><td style=\"text-align: right;\">2.92086e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.525298</td><td style=\"text-align: right;\">2.91681</td><td style=\"text-align: right;\">0.652158</td><td style=\"text-align: right;\">  0.972277</td></tr>\n",
       "<tr><td>fresh_start_c7281754</td><td>TERMINATED</td><td>172.21.93.86:25909</td><td style=\"text-align: right;\">  0.0328906</td><td style=\"text-align: right;\">       780</td><td style=\"text-align: right;\">0.00156261 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.715757</td><td style=\"text-align: right;\">2.87704</td><td style=\"text-align: right;\">1.00227 </td><td style=\"text-align: right;\">  0.959101</td></tr>\n",
       "<tr><td>fresh_start_c86b2552</td><td>TERMINATED</td><td>172.21.93.86:25940</td><td style=\"text-align: right;\"> 22.7906   </td><td style=\"text-align: right;\">      5780</td><td style=\"text-align: right;\">0.0027725  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.24519 </td><td style=\"text-align: right;\">2.78289</td><td style=\"text-align: right;\">1.66538 </td><td style=\"text-align: right;\">  0.927734</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:20,142\tWARNING worker.py:1829 -- Warning: The actor ImplicitFunc is very large (84 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2022-11-01 17:11:20,459\tWARNING util.py:244 -- The `start_trial` operation took 1.761 s, which may be a performance bottleneck.\n",
      "2022-11-01 17:11:24,333\tWARNING util.py:244 -- The `start_trial` operation took 0.719 s, which may be a performance bottleneck.\n",
      "2022-11-01 17:11:26,387\tWARNING util.py:244 -- The `start_trial` operation took 0.781 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_b9e48de8:\n",
      "  accuracy: 0.9263716574269667\n",
      "  date: 2022-11-01_17-11-26\n",
      "  done: false\n",
      "  experiment_id: da3514c7a8204656a7cb329802368ee6\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.704023960264476\n",
      "  model: \"LogisticRegression(C=221.3077217918963, max_iter=3540.0, random_state=0,\\n\\\n",
      "    \\                   tol=6.8467783184126e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 221.3077217918963\n",
      "    max_iter: 3540.0\n",
      "    tol: 6.8467783184126e-05\n",
      "  pid: 25712\n",
      "  precision: 0.9304029304029304\n",
      "  recall: 0.9219600725952813\n",
      "  score: 2.7787346604251786\n",
      "  time_since_restore: 4.228104114532471\n",
      "  time_this_iter_s: 4.228104114532471\n",
      "  time_total_s: 4.228104114532471\n",
      "  timestamp: 1667337086\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: b9e48de8\n",
      "  warmup_time: 0.003507852554321289\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:30,342\tWARNING util.py:244 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_b9e48de8:\n",
      "  accuracy: 0.9263716574269667\n",
      "  date: 2022-11-01_17-11-26\n",
      "  done: true\n",
      "  experiment_id: da3514c7a8204656a7cb329802368ee6\n",
      "  experiment_tag: 1_C=221.3077,max_iter=3540.0000,tol=0.0001\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.704023960264476\n",
      "  model: \"LogisticRegression(C=221.3077217918963, max_iter=3540.0, random_state=0,\\n\\\n",
      "    \\                   tol=6.8467783184126e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 221.3077217918963\n",
      "    max_iter: 3540.0\n",
      "    tol: 6.8467783184126e-05\n",
      "  pid: 25712\n",
      "  precision: 0.9304029304029304\n",
      "  recall: 0.9219600725952813\n",
      "  score: 2.7787346604251786\n",
      "  time_since_restore: 4.228104114532471\n",
      "  time_this_iter_s: 4.228104114532471\n",
      "  time_total_s: 4.228104114532471\n",
      "  timestamp: 1667337086\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: b9e48de8\n",
      "  warmup_time: 0.003507852554321289\n",
      "  \n",
      "Result for fresh_start_bcaf0896:\n",
      "  accuracy: 0.9468237911530286\n",
      "  date: 2022-11-01_17-11-28\n",
      "  done: false\n",
      "  experiment_id: 6426518752b044fbb91c2a97bba15922\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.2286313796033372\n",
      "  model: \"LogisticRegression(C=0.18927476436176804, max_iter=6920.0, random_state=0,\\n\\\n",
      "    \\                   tol=5.916608230654473e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.18927476436176804\n",
      "    max_iter: 6920.0\n",
      "    tol: 5.916608230654473e-05\n",
      "  pid: 25741\n",
      "  precision: 0.9497716894977168\n",
      "  recall: 0.9437386569872959\n",
      "  score: 2.8403341376380413\n",
      "  time_since_restore: 0.661552906036377\n",
      "  time_this_iter_s: 0.661552906036377\n",
      "  time_total_s: 0.661552906036377\n",
      "  timestamp: 1667337088\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bcaf0896\n",
      "  warmup_time: 0.0045087337493896484\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:31,910\tWARNING util.py:244 -- The `start_trial` operation took 0.729 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_bdd4f2a8:\n",
      "  accuracy: 0.9454609767305016\n",
      "  date: 2022-11-01_17-11-29\n",
      "  done: false\n",
      "  experiment_id: ad9ffb018868486b9ac13846a83b75f0\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.2672518239941235\n",
      "  model: \"LogisticRegression(C=0.23313398718833941, max_iter=6750.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.013697326625803039)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.23313398718833941\n",
      "    max_iter: 6750.0\n",
      "    tol: 0.013697326625803039\n",
      "  pid: 25748\n",
      "  precision: 0.9488117001828154\n",
      "  recall: 0.941923774954628\n",
      "  score: 2.836196451867945\n",
      "  time_since_restore: 0.755042314529419\n",
      "  time_this_iter_s: 0.755042314529419\n",
      "  time_total_s: 0.755042314529419\n",
      "  timestamp: 1667337089\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bdd4f2a8\n",
      "  warmup_time: 0.003267049789428711\n",
      "  \n",
      "Result for fresh_start_bcaf0896:\n",
      "  accuracy: 0.9468237911530286\n",
      "  date: 2022-11-01_17-11-28\n",
      "  done: true\n",
      "  experiment_id: 6426518752b044fbb91c2a97bba15922\n",
      "  experiment_tag: 2_C=0.1893,max_iter=6920.0000,tol=0.0001\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.2286313796033372\n",
      "  model: \"LogisticRegression(C=0.18927476436176804, max_iter=6920.0, random_state=0,\\n\\\n",
      "    \\                   tol=5.916608230654473e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.18927476436176804\n",
      "    max_iter: 6920.0\n",
      "    tol: 5.916608230654473e-05\n",
      "  pid: 25741\n",
      "  precision: 0.9497716894977168\n",
      "  recall: 0.9437386569872959\n",
      "  score: 2.8403341376380413\n",
      "  time_since_restore: 0.661552906036377\n",
      "  time_this_iter_s: 0.661552906036377\n",
      "  time_total_s: 0.661552906036377\n",
      "  timestamp: 1667337088\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bcaf0896\n",
      "  warmup_time: 0.0045087337493896484\n",
      "  \n",
      "Result for fresh_start_bdd4f2a8:\n",
      "  accuracy: 0.9454609767305016\n",
      "  date: 2022-11-01_17-11-29\n",
      "  done: true\n",
      "  experiment_id: ad9ffb018868486b9ac13846a83b75f0\n",
      "  experiment_tag: 3_C=0.2331,max_iter=6750.0000,tol=0.0137\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.2672518239941235\n",
      "  model: \"LogisticRegression(C=0.23313398718833941, max_iter=6750.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.013697326625803039)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.23313398718833941\n",
      "    max_iter: 6750.0\n",
      "    tol: 0.013697326625803039\n",
      "  pid: 25748\n",
      "  precision: 0.9488117001828154\n",
      "  recall: 0.941923774954628\n",
      "  score: 2.836196451867945\n",
      "  time_since_restore: 0.755042314529419\n",
      "  time_this_iter_s: 0.755042314529419\n",
      "  time_total_s: 0.755042314529419\n",
      "  timestamp: 1667337089\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bdd4f2a8\n",
      "  warmup_time: 0.003267049789428711\n",
      "  \n",
      "Result for fresh_start_c16acd84:\n",
      "  accuracy: 0.951372566520881\n",
      "  date: 2022-11-01_17-11-35\n",
      "  done: false\n",
      "  experiment_id: 057953aa9a4a4e69a3053dea9fc9fc07\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1634041663920298\n",
      "  model: \"LogisticRegression(C=0.11756937902669257, max_iter=9000.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.006215607934976419)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.11756937902669257\n",
      "    max_iter: 9000.0\n",
      "    tol: 0.006215607934976419\n",
      "  pid: 25833\n",
      "  precision: 0.9560036663611365\n",
      "  recall: 0.9464609800362976\n",
      "  score: 2.853837212918315\n",
      "  time_since_restore: 1.0257956981658936\n",
      "  time_this_iter_s: 1.0257956981658936\n",
      "  time_total_s: 1.0257956981658936\n",
      "  timestamp: 1667337095\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c16acd84\n",
      "  warmup_time: 0.006397247314453125\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:37,317\tWARNING util.py:244 -- The `start_trial` operation took 0.654 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_c083f26a:\n",
      "  accuracy: 0.9272807513413268\n",
      "  date: 2022-11-01_17-11-35\n",
      "  done: false\n",
      "  experiment_id: 27bb168a4db74503a0ecfc96a86d8cc5\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6840502951076872\n",
      "  model: \"LogisticRegression(C=29.543062769662203, max_iter=8490.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.00030063475326946263)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 29.543062769662203\n",
      "    max_iter: 8490.0\n",
      "    tol: 0.00030063475326946263\n",
      "  pid: 25804\n",
      "  precision: 0.9313186813186813\n",
      "  recall: 0.9228675136116152\n",
      "  score: 2.7814669462716237\n",
      "  time_since_restore: 2.5757622718811035\n",
      "  time_this_iter_s: 2.5757622718811035\n",
      "  time_total_s: 2.5757622718811035\n",
      "  timestamp: 1667337095\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c083f26a\n",
      "  warmup_time: 0.003150463104248047\n",
      "  \n",
      "Result for fresh_start_c16acd84:\n",
      "  accuracy: 0.951372566520881\n",
      "  date: 2022-11-01_17-11-35\n",
      "  done: true\n",
      "  experiment_id: 057953aa9a4a4e69a3053dea9fc9fc07\n",
      "  experiment_tag: 5_C=0.1176,max_iter=9000.0000,tol=0.0062\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1634041663920298\n",
      "  model: \"LogisticRegression(C=0.11756937902669257, max_iter=9000.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.006215607934976419)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.11756937902669257\n",
      "    max_iter: 9000.0\n",
      "    tol: 0.006215607934976419\n",
      "  pid: 25833\n",
      "  precision: 0.9560036663611365\n",
      "  recall: 0.9464609800362976\n",
      "  score: 2.853837212918315\n",
      "  time_since_restore: 1.0257956981658936\n",
      "  time_this_iter_s: 1.0257956981658936\n",
      "  time_total_s: 1.0257956981658936\n",
      "  timestamp: 1667337095\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c16acd84\n",
      "  warmup_time: 0.006397247314453125\n",
      "  \n",
      "Result for fresh_start_c083f26a:\n",
      "  accuracy: 0.9272807513413268\n",
      "  date: 2022-11-01_17-11-35\n",
      "  done: true\n",
      "  experiment_id: 27bb168a4db74503a0ecfc96a86d8cc5\n",
      "  experiment_tag: 4_C=29.5431,max_iter=8490.0000,tol=0.0003\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6840502951076872\n",
      "  model: \"LogisticRegression(C=29.543062769662203, max_iter=8490.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.00030063475326946263)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 29.543062769662203\n",
      "    max_iter: 8490.0\n",
      "    tol: 0.00030063475326946263\n",
      "  pid: 25804\n",
      "  precision: 0.9313186813186813\n",
      "  recall: 0.9228675136116152\n",
      "  score: 2.7814669462716237\n",
      "  time_since_restore: 2.5757622718811035\n",
      "  time_this_iter_s: 2.5757622718811035\n",
      "  time_total_s: 2.5757622718811035\n",
      "  timestamp: 1667337095\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c083f26a\n",
      "  warmup_time: 0.003150463104248047\n",
      "  \n",
      "Result for fresh_start_c696e676:\n",
      "  accuracy: 0.9722767678570838\n",
      "  date: 2022-11-01_17-11-40\n",
      "  done: false\n",
      "  experiment_id: 27bb168a4db74503a0ecfc96a86d8cc5\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6521584597145641\n",
      "  model: \"LogisticRegression(C=0.0031039009824053426, max_iter=5100.0, random_state=0,\\n\\\n",
      "    \\                   tol=2.920856784232474e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.0031039009824053426\n",
      "    max_iter: 5100.0\n",
      "    tol: 2.920856784232474e-05\n",
      "  pid: 25804\n",
      "  precision: 0.9744758432087511\n",
      "  recall: 0.97005444646098\n",
      "  score: 2.9168070575268152\n",
      "  time_since_restore: 0.5252981185913086\n",
      "  time_this_iter_s: 0.5252981185913086\n",
      "  time_total_s: 0.5252981185913086\n",
      "  timestamp: 1667337100\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c696e676\n",
      "  warmup_time: 0.003150463104248047\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:42,078\tWARNING util.py:244 -- The `start_trial` operation took 0.785 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_c696e676:\n",
      "  accuracy: 0.9722767678570838\n",
      "  date: 2022-11-01_17-11-40\n",
      "  done: true\n",
      "  experiment_id: 27bb168a4db74503a0ecfc96a86d8cc5\n",
      "  experiment_tag: 8_C=0.0031,max_iter=5100.0000,tol=0.0000\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6521584597145641\n",
      "  model: \"LogisticRegression(C=0.0031039009824053426, max_iter=5100.0, random_state=0,\\n\\\n",
      "    \\                   tol=2.920856784232474e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.0031039009824053426\n",
      "    max_iter: 5100.0\n",
      "    tol: 2.920856784232474e-05\n",
      "  pid: 25804\n",
      "  precision: 0.9744758432087511\n",
      "  recall: 0.97005444646098\n",
      "  score: 2.9168070575268152\n",
      "  time_since_restore: 0.5252981185913086\n",
      "  time_this_iter_s: 0.5252981185913086\n",
      "  time_total_s: 0.5252981185913086\n",
      "  timestamp: 1667337100\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c696e676\n",
      "  warmup_time: 0.003150463104248047\n",
      "  \n",
      "Result for fresh_start_c49f36fc:\n",
      "  accuracy: 0.9286435657638538\n",
      "  date: 2022-11-01_17-11-42\n",
      "  done: false\n",
      "  experiment_id: c1382b051f0c45c7b50699694f66114c\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6454120895115087\n",
      "  model: \"LogisticRegression(C=8.650521578122575, max_iter=2690.0, random_state=0,\\n\\\n",
      "    \\                   tol=4.118471104686137e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 8.650521578122575\n",
      "    max_iter: 2690.0\n",
      "    tol: 4.118471104686137e-05\n",
      "  pid: 25872\n",
      "  precision: 0.9322964318389753\n",
      "  recall: 0.9246823956442831\n",
      "  score: 2.7856223932471122\n",
      "  time_since_restore: 3.104220390319824\n",
      "  time_this_iter_s: 3.104220390319824\n",
      "  time_total_s: 3.104220390319824\n",
      "  timestamp: 1667337102\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c49f36fc\n",
      "  warmup_time: 0.00325775146484375\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:45,035\tWARNING util.py:244 -- The `start_trial` operation took 0.872 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for fresh_start_c3ef62d6:\n",
      "  accuracy: 0.9359163170787341\n",
      "  date: 2022-11-01_17-11-37\n",
      "  done: false\n",
      "  experiment_id: ad9ffb018868486b9ac13846a83b75f0\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.4856294709171407\n",
      "  model: \"LogisticRegression(C=0.8503058036376933, max_iter=7430.0, random_state=0,\\n\\\n",
      "    \\                   tol=5.7750271411559474e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.8503058036376933\n",
      "    max_iter: 7430.0\n",
      "    tol: 5.7750271411559474e-05\n",
      "  pid: 25748\n",
      "  precision: 0.939615736505032\n",
      "  recall: 0.9319419237749547\n",
      "  score: 2.807473977358721\n",
      "  time_since_restore: 1.5985937118530273\n",
      "  time_this_iter_s: 1.5985937118530273\n",
      "  time_total_s: 1.5985937118530273\n",
      "  timestamp: 1667337097\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c3ef62d6\n",
      "  warmup_time: 0.003267049789428711\n",
      "  \n",
      "Result for fresh_start_c7281754:\n",
      "  accuracy: 0.9591006912419545\n",
      "  date: 2022-11-01_17-11-44\n",
      "  done: false\n",
      "  experiment_id: 8cf205d7366f45a6961b1b2b28f66e97\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0022689619324234\n",
      "  model: \"LogisticRegression(C=0.0328905626322735, max_iter=780.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.001562607723428894)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.0328905626322735\n",
      "    max_iter: 780.0\n",
      "    tol: 0.001562607723428894\n",
      "  pid: 25909\n",
      "  precision: 0.9642201834862385\n",
      "  recall: 0.9537205081669692\n",
      "  score: 2.877041382895162\n",
      "  time_since_restore: 0.7157566547393799\n",
      "  time_this_iter_s: 0.7157566547393799\n",
      "  time_total_s: 0.7157566547393799\n",
      "  timestamp: 1667337104\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c7281754\n",
      "  warmup_time: 0.003840208053588867\n",
      "  \n",
      "Result for fresh_start_c49f36fc:\n",
      "  accuracy: 0.9286435657638538\n",
      "  date: 2022-11-01_17-11-42\n",
      "  done: true\n",
      "  experiment_id: c1382b051f0c45c7b50699694f66114c\n",
      "  experiment_tag: 7_C=8.6505,max_iter=2690.0000,tol=0.0000\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6454120895115087\n",
      "  model: \"LogisticRegression(C=8.650521578122575, max_iter=2690.0, random_state=0,\\n\\\n",
      "    \\                   tol=4.118471104686137e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 8.650521578122575\n",
      "    max_iter: 2690.0\n",
      "    tol: 4.118471104686137e-05\n",
      "  pid: 25872\n",
      "  precision: 0.9322964318389753\n",
      "  recall: 0.9246823956442831\n",
      "  score: 2.7856223932471122\n",
      "  time_since_restore: 3.104220390319824\n",
      "  time_this_iter_s: 3.104220390319824\n",
      "  time_total_s: 3.104220390319824\n",
      "  timestamp: 1667337102\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c49f36fc\n",
      "  warmup_time: 0.00325775146484375\n",
      "  \n",
      "Result for fresh_start_c7281754:\n",
      "  accuracy: 0.9591006912419545\n",
      "  date: 2022-11-01_17-11-44\n",
      "  done: true\n",
      "  experiment_id: 8cf205d7366f45a6961b1b2b28f66e97\n",
      "  experiment_tag: 9_C=0.0329,max_iter=780.0000,tol=0.0016\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0022689619324234\n",
      "  model: \"LogisticRegression(C=0.0328905626322735, max_iter=780.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.001562607723428894)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.0328905626322735\n",
      "    max_iter: 780.0\n",
      "    tol: 0.001562607723428894\n",
      "  pid: 25909\n",
      "  precision: 0.9642201834862385\n",
      "  recall: 0.9537205081669692\n",
      "  score: 2.877041382895162\n",
      "  time_since_restore: 0.7157566547393799\n",
      "  time_this_iter_s: 0.7157566547393799\n",
      "  time_total_s: 0.7157566547393799\n",
      "  timestamp: 1667337104\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c7281754\n",
      "  warmup_time: 0.003840208053588867\n",
      "  \n",
      "Result for fresh_start_c3ef62d6:\n",
      "  accuracy: 0.9359163170787341\n",
      "  date: 2022-11-01_17-11-37\n",
      "  done: true\n",
      "  experiment_id: ad9ffb018868486b9ac13846a83b75f0\n",
      "  experiment_tag: 6_C=0.8503,max_iter=7430.0000,tol=0.0001\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.4856294709171407\n",
      "  model: \"LogisticRegression(C=0.8503058036376933, max_iter=7430.0, random_state=0,\\n\\\n",
      "    \\                   tol=5.7750271411559474e-05)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 0.8503058036376933\n",
      "    max_iter: 7430.0\n",
      "    tol: 5.7750271411559474e-05\n",
      "  pid: 25748\n",
      "  precision: 0.939615736505032\n",
      "  recall: 0.9319419237749547\n",
      "  score: 2.807473977358721\n",
      "  time_since_restore: 1.5985937118530273\n",
      "  time_this_iter_s: 1.5985937118530273\n",
      "  time_total_s: 1.5985937118530273\n",
      "  timestamp: 1667337097\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c3ef62d6\n",
      "  warmup_time: 0.003267049789428711\n",
      "  \n",
      "Result for fresh_start_c86b2552:\n",
      "  accuracy: 0.9277344718494938\n",
      "  date: 2022-11-01_17-11-48\n",
      "  done: false\n",
      "  experiment_id: 7d4ac4425c4e4ffda3defa6a15da7640\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6653849168358035\n",
      "  model: \"LogisticRegression(C=22.790556518263443, max_iter=5780.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.0027725004092497767)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 22.790556518263443\n",
      "    max_iter: 5780.0\n",
      "    tol: 0.0027725004092497767\n",
      "  pid: 25940\n",
      "  precision: 0.9313815187557182\n",
      "  recall: 0.9237749546279492\n",
      "  score: 2.782890945233161\n",
      "  time_since_restore: 1.2451872825622559\n",
      "  time_this_iter_s: 1.2451872825622559\n",
      "  time_total_s: 1.2451872825622559\n",
      "  timestamp: 1667337108\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c86b2552\n",
      "  warmup_time: 0.0030548572540283203\n",
      "  \n",
      "Result for fresh_start_c86b2552:\n",
      "  accuracy: 0.9277344718494938\n",
      "  date: 2022-11-01_17-11-48\n",
      "  done: true\n",
      "  experiment_id: 7d4ac4425c4e4ffda3defa6a15da7640\n",
      "  experiment_tag: 10_C=22.7906,max_iter=5780.0000,tol=0.0028\n",
      "  hostname: King-George-The-V\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6653849168358035\n",
      "  model: \"LogisticRegression(C=22.790556518263443, max_iter=5780.0, random_state=0,\\n\\\n",
      "    \\                   tol=0.0027725004092497767)\"\n",
      "  node_ip: 172.21.93.86\n",
      "  params:\n",
      "    C: 22.790556518263443\n",
      "    max_iter: 5780.0\n",
      "    tol: 0.0027725004092497767\n",
      "  pid: 25940\n",
      "  precision: 0.9313815187557182\n",
      "  recall: 0.9237749546279492\n",
      "  score: 2.782890945233161\n",
      "  time_since_restore: 1.2451872825622559\n",
      "  time_this_iter_s: 1.2451872825622559\n",
      "  time_total_s: 1.2451872825622559\n",
      "  timestamp: 1667337108\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c86b2552\n",
      "  warmup_time: 0.0030548572540283203\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:11:48,960\tINFO tune.py:758 -- Total run time: 32.28 seconds (31.10 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "\n",
    "best_result = results.get_best_result()  # Get best result object\n",
    "best_config = best_result.config  # Get best trial's hyperparameters\n",
    "best_logdir = best_result.log_dir  # Get best trial's logdir\n",
    "best_checkpoint = best_result.checkpoint  # Get best trial's best checkpoint\n",
    "best_metrics = best_result.metrics  # Get best trial's last results\n",
    "best_result_df = best_result.metrics_dataframe  # Get best result as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 2.9168070575268152,\n",
       " 'loss': 0.6521584597145641,\n",
       " 'model': LogisticRegression(C=0.0031039009824053426, max_iter=5100.0, random_state=0,\n",
       "                    tol=2.920856784232474e-05),\n",
       " 'params': {'max_iter': 5100.0,\n",
       "  'tol': 2.920856784232474e-05,\n",
       "  'C': 0.0031039009824053426},\n",
       " 'accuracy': 0.9722767678570838,\n",
       " 'precision': 0.9744758432087511,\n",
       " 'recall': 0.97005444646098,\n",
       " 'time_this_iter_s': 0.5252981185913086,\n",
       " 'done': True,\n",
       " 'timesteps_total': None,\n",
       " 'episodes_total': None,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'c696e676',\n",
       " 'experiment_id': '27bb168a4db74503a0ecfc96a86d8cc5',\n",
       " 'date': '2022-11-01_17-11-40',\n",
       " 'timestamp': 1667337100,\n",
       " 'time_total_s': 0.5252981185913086,\n",
       " 'pid': 25804,\n",
       " 'hostname': 'King-George-The-V',\n",
       " 'node_ip': '172.21.93.86',\n",
       " 'config': {'max_iter': 5100.0,\n",
       "  'tol': 2.920856784232474e-05,\n",
       "  'C': 0.0031039009824053426},\n",
       " 'time_since_restore': 0.5252981185913086,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 1,\n",
       " 'warmup_time': 0.003150463104248047,\n",
       " 'experiment_tag': '8_C=0.0031,max_iter=5100.0000,tol=0.0000'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
